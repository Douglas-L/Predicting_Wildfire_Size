{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "In this notebook, I mention two possible ways of gathering weather data and appending it to the fires data and go into the Google BigQuery method in detail. I will explore the new columns of the full data set in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "[Method 1: NCDC API](#method1)  \n",
    "[Method 2: Google BigQuery](#method2)\n",
    "1. [US Weather Station IDs](#usids)\n",
    "2. [Pull Weather from GBQ](#gbqweather)\n",
    "3. [State to Station Dictionary](#state2station)\n",
    "4. [Find Nearest Stations](#near)\n",
    "5. [Join Weather](#join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='method1'></a>\n",
    "# Method 1: NCDC API\n",
    "One way to get the weather at a given location is through the National Climatic Data Center (NCDC). I tried this during Take 1 to retrieve precipitation, temperature, and average wind speed for my small subsets but was unable to scale it up for the whole dataset. Look at 'Fires 6 scrape weather' for details.\n",
    "\n",
    "#### NCDC API\n",
    "Pros:\n",
    "- Can retrieve all the stations associated with a FIPS code, allowing you to calculate an average \n",
    "- Potentially more features from a weather station\n",
    "\n",
    "Cons:\n",
    "- Can only get multiple dates at a time if looking up one specific station \n",
    "- Data coverage is spotty at best for features outside the standard ones like temperature and precipitation\n",
    "- maximum 10000 API requests per key per day - not ideal for a lot of look ups given how restricted the queries are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='method2'></a>\n",
    "# Method 2: Google BigQuery\n",
    "\n",
    "Google BigQuery(GBQ) hosts multiple weather data sets, including two from the NOAA* that are updated daily, GHCN** and GSOD***. I decided to query GSOD because the data has thorough descriptions and the schema is easier to work with. The rows are stations on a given day and the columns are the weather features. The data set is divided into separate tables for different years. \n",
    "\n",
    "I want to join my fire records to the corresponding weather data. To minimize the data involved for the join, it is imperative to filter the weather data first. \n",
    "\n",
    "\\*National Oceanic and Atmospheric Administration  \n",
    "\\*\\*Global Historical Climatology Network  \n",
    "\\*\\*\\* Global Surface Summary of the Day  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='usids'></a>\n",
    "### Step 1. Filter for US only stations\n",
    "\n",
    "You can try getting the station information from GBQ\n",
    "\n",
    "```\n",
    "SELECT usaf, wban, country, state, lat, lon, begin, `end`  \n",
    "FROM `bigquery-public-data.noaa_gsod.stations`\n",
    "WHERE country = 'US'\n",
    "```\n",
    "\n",
    "However, when looking up descriptions for the columns, I found you can download the Integrated Surface Database Station History from the NOAA ftp server. The .txt version has the descriptions while the .csv contains the data only. \n",
    "\n",
    "isd_stations_url = 'ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv'\n",
    "\n",
    "Quick filter with bash\n",
    "```\n",
    "! cat isd-history.csv | grep \\\"US\\\" > us_only_stations.csv\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>621010</td>\n",
       "      <td>99999</td>\n",
       "      <td>MOORED BUOY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.6</td>\n",
       "      <td>-2.933</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>20080721</td>\n",
       "      <td>20080721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621110</td>\n",
       "      <td>99999</td>\n",
       "      <td>MOORED BUOY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>20041118</td>\n",
       "      <td>20041118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621130</td>\n",
       "      <td>99999</td>\n",
       "      <td>MOORED BUOY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>20040726</td>\n",
       "      <td>20040726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>621160</td>\n",
       "      <td>99999</td>\n",
       "      <td>MOORED BUOY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.1</td>\n",
       "      <td>1.800</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>20040829</td>\n",
       "      <td>20040829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>621170</td>\n",
       "      <td>99999</td>\n",
       "      <td>MOORED BUOY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>20040726</td>\n",
       "      <td>20040726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USAF   WBAN STATION NAME CTRY   ST CALL   LAT    LON  ELEV(M)     BEGIN  \\\n",
       "0  621010  99999  MOORED BUOY   US  NaN  NaN  50.6 -2.933   -999.0  20080721   \n",
       "1  621110  99999  MOORED BUOY   US  NaN  NaN  58.9 -0.200   -999.0  20041118   \n",
       "2  621130  99999  MOORED BUOY   US  NaN  NaN  58.4  0.300   -999.0  20040726   \n",
       "3  621160  99999  MOORED BUOY   US  NaN  NaN  58.1  1.800   -999.0  20040829   \n",
       "4  621170  99999  MOORED BUOY   US  NaN  NaN  57.9  0.100   -999.0  20040726   \n",
       "\n",
       "        END  \n",
       "0  20080721  \n",
       "1  20041118  \n",
       "2  20040726  \n",
       "3  20040829  \n",
       "4  20040726  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'us_only_stations.csv'\n",
    "all_stations = pd.read_csv(csv_path, header=None,\n",
    "                           names=['USAF', 'WBAN', 'STATION NAME', 'CTRY', 'ST',\n",
    "                                  'CALL', 'LAT', 'LON', 'ELEV(M)', 'BEGIN',  'END'])\n",
    "all_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USAF            7370\n",
       "WBAN            7370\n",
       "STATION NAME    7316\n",
       "CTRY            7370\n",
       "ST              6672\n",
       "CALL            5073\n",
       "LAT             7249\n",
       "LON             7249\n",
       "ELEV(M)         7249\n",
       "BEGIN           7370\n",
       "END             7370\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5868 stations with data beyond 1992\n",
      "64 stations with nulls\n"
     ]
    }
   ],
   "source": [
    "# keep only those that have relevant dates and valid coordinates\n",
    "stations_has_data_beyond_1992 = all_stations[all_stations['END'] // 10000 > 1992]\n",
    "drop_nulls = stations_has_data_beyond_1992.dropna(axis=0,\n",
    "                                                  subset=['LAT', 'LON', 'BEGIN', 'END'])\n",
    "print(len(stations_has_data_beyond_1992), 'stations with data beyond 1992')\n",
    "print(len(stations_has_data_beyond_1992) - len(drop_nulls), 'stations with nulls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USAF            3774\n",
       "WBAN            2487\n",
       "STATION NAME    5485\n",
       "CTRY               1\n",
       "ST                53\n",
       "CALL            2448\n",
       "LAT             3722\n",
       "LON             4326\n",
       "ELEV(M)         2406\n",
       "BEGIN           1711\n",
       "END              756\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_nulls.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     3265\n",
       "0      501\n",
       "2        7\n",
       "48       1\n",
       "Name: ST, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USAF not unique within a state\n",
    "drop_nulls.groupby('USAF')['ST'].nunique().sort_values(ascending=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>996350</td>\n",
       "      <td>99999</td>\n",
       "      <td>ST. AUGUSTINE  FL 40NM ENE OF ST AUGUSTI</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-80.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20020626</td>\n",
       "      <td>20101231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        USAF   WBAN                              STATION NAME CTRY   ST CALL  \\\n",
       "5509  996350  99999  ST. AUGUSTINE  FL 40NM ENE OF ST AUGUSTI   US  NaN  NaN   \n",
       "\n",
       "       LAT   LON  ELEV(M)     BEGIN       END  \n",
       "5509  30.0 -80.6      0.0  20020626  20101231  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_nulls[drop_nulls['USAF'] == '996350']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5804, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>722212</td>\n",
       "      <td>92814</td>\n",
       "      <td>ST AUGUSTINE AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>KSGJ</td>\n",
       "      <td>29.959</td>\n",
       "      <td>-81.340</td>\n",
       "      <td>3.1</td>\n",
       "      <td>20060101</td>\n",
       "      <td>20181023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>722212</td>\n",
       "      <td>99999</td>\n",
       "      <td>ST AUGUSTINE</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>KSGJ</td>\n",
       "      <td>29.967</td>\n",
       "      <td>-81.333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19970123</td>\n",
       "      <td>20071231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>994410</td>\n",
       "      <td>99999</td>\n",
       "      <td>ST. AUGUSTINE  FL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.860</td>\n",
       "      <td>-81.260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19870122</td>\n",
       "      <td>20180425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>994700</td>\n",
       "      <td>99999</td>\n",
       "      <td>AUGUSTINE ISLAND</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.380</td>\n",
       "      <td>-153.350</td>\n",
       "      <td>9.1</td>\n",
       "      <td>20020703</td>\n",
       "      <td>20180425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>996350</td>\n",
       "      <td>99999</td>\n",
       "      <td>ST. AUGUSTINE  FL 40NM ENE OF ST AUGUSTI</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000</td>\n",
       "      <td>-80.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20020626</td>\n",
       "      <td>20101231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        USAF   WBAN                              STATION NAME CTRY   ST  CALL  \\\n",
       "1674  722212  92814                      ST AUGUSTINE AIRPORT   US   FL  KSGJ   \n",
       "1675  722212  99999                              ST AUGUSTINE   US   FL  KSGJ   \n",
       "5408  994410  99999                         ST. AUGUSTINE  FL   US  NaN   NaN   \n",
       "5433  994700  99999                          AUGUSTINE ISLAND   US   AK   NaN   \n",
       "5509  996350  99999  ST. AUGUSTINE  FL 40NM ENE OF ST AUGUSTI   US  NaN   NaN   \n",
       "\n",
       "         LAT      LON  ELEV(M)     BEGIN       END  \n",
       "1674  29.959  -81.340      3.1  20060101  20181023  \n",
       "1675  29.967  -81.333      3.0  19970123  20071231  \n",
       "5408  29.860  -81.260      0.0  19870122  20180425  \n",
       "5433  59.380 -153.350      9.1  20020703  20180425  \n",
       "5509  30.000  -80.600      0.0  20020626  20101231  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's possible you miss out on some closer stations but coverage should be adequate\n",
    "drop_nulls[drop_nulls['STATION NAME'].str.contains('AUGUSTINE')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbqweather'></a>\n",
    "### Step 2: Pull US weather data from GBQ\n",
    "Won't run here since already downloaded in 'gbq_get_weather' notebook. The idea is filter each year's GBQ table for only the stations in the list of US station IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stations = drop_nulls['USAF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3774"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple gives the commas necessary to be read as a list in str form\n",
    "us_stations2 = tuple(us_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python API for GBQ\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "# set credentials with oauth2 , set up your own json credentials\n",
    "credentials = service_account.Credentials.from_service_account_file('/home/douglas/Downloads/weather-5deec6be7e9f.json')\n",
    "# create client for weather project using above service acount credentials\n",
    "client = bigquery.Client(project='weather-214817', credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the columns I queried but there are a few more available.\n",
    "\n",
    "Columns | Description\n",
    " ----- | -----\n",
    "stn | station ID - USAF in isd-history\n",
    "year | year\n",
    "mo | month\n",
    "da | day\n",
    "temp | Mean temperature for the day in degrees Fahrenheit to tenths. Missing = 9999.9\n",
    "stp | Mean station pressure for the day in millibars to tenths. Missing = 9999.9\n",
    "wdsp | Mean wind speed for the day in knots to tenths. Missing = 999.9\n",
    "max | Maximum temperature reported during the day in Fahrenheit to tenths. Missing = 9999.9\n",
    "prcp | Total precipitation (rain and/or melted snow) reported during the day in inches and hundredths; Many stations do not report '0' on days with no precipitation--therefore, '99.99' \n",
    "thunder | Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/douglas/ds_projects/Predicting_Wildfire_Size/data'\n",
    "\n",
    "\n",
    "def pull_us_weather(us_stations, out_dir):\n",
    "    '''Download weather data for US stations\n",
    "    \n",
    "    '''\n",
    "    # Get names and queries ready\n",
    "    df_names = ['weather' + str(yr) for yr in np.arange(1992,2016,1)]\n",
    "    queries = ['''SELECT stn, year, mo, da, temp, stp, wdsp, max as max_temp, prcp, thunder  \n",
    "        FROM `bigquery-public-data.noaa_gsod.gsod{}` \n",
    "        WHERE stn IN {} order by stn, mo'''.format(str(yr), tuple(us_stations)) for yr in np.arange(1992,2016)]\n",
    "    \n",
    "    # Store pulled dataframes in a dict, with key=year, value=df\n",
    "    weather_dfs = dict()\n",
    "    for year, query in zip(df_names, queries):\n",
    "        query_job = client.query(query)\n",
    "        rows = query_job.result()\n",
    "        weather_dfs[year] = rows.to_dataframe()\n",
    "        print(year, 'downloaded')  \n",
    "            \n",
    "    # Pickle dataframes\n",
    "    for name in df_names:\n",
    "        df = weather_dfs[name]\n",
    "        with open(f'{out_dir}/{name}.pkl', 'wb') as picklefile:\n",
    "            pickle.dump(df, picklefile)\n",
    "        print(name, 'saved')\n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample timings for the two loops within 'pull_us_weather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "weather_dfs = dict()\n",
    "for year, query in zip(df_names, queries):\n",
    "    query_job = client.query(query)\n",
    "    rows = query_job.result()\n",
    "    weather_dfs[year] = rows.to_dataframe()\n",
    "    print(year, 'downloaded')   \n",
    "```\n",
    "CPU times: user 7min 19s, sys: 11.3 s, total: 7min 30s\n",
    "Wall time: 31min 59s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for name in df_names:\n",
    "    df = weather_dfs[name]\n",
    "    with open('/home/douglas/ds_projects/Predicting_Wildfire_Size/data/{}.pkl'.format(name), 'wb') as picklefile:\n",
    "        pickle.dump(df, picklefile)\n",
    "    print(name, 'saved')\n",
    "```\n",
    "CPU times: user 36.1 s, sys: 21.5 s, total: 57.6 s\n",
    "Wall time: 47min 28s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some issues with the data returning from these queries that caused extra rows when joining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather_data(weather_df):\n",
    "    '''convert int date format to pd.datetime and remove duplicate station id and date combinations'''\n",
    "    original_length = len(weather_df)\n",
    "    weather_df = weather_df[weather_df['stn'] != '999999'] # DROP STATIONS THAT USE WBAN INDEX INSTEAD OF USAF   \n",
    "    weather_df['date'] = (weather_df['year'] + weather_df['mo'] + weather_df['da']).astype('int') \n",
    "    weather_df['date'] = pd.to_datetime(weather_df['date'], format='%Y%m%d') # deal with month/year changing\n",
    "    weather_df = weather_df.sort_values(['stn', 'date']) # sort before looking for dupes\n",
    "    dupe_mask = weather_df[['stn', 'date']].duplicated() # 'Mark duplicates as true except for the first occurence'\n",
    "    weather_df = weather_df[~dupe_mask] # keep only non dupes \n",
    "\n",
    "    print('Rows before and after trimming:', original_length, len(weather_df))\n",
    "    print('sample cols', weather_df[['date', 'stn']].sample(1))\n",
    "\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment below to apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_files = sorted([p for p in os.listdir('./data/') if 'weather' in p])\n",
    "\n",
    "# # Apply cleaning to weather dataframes\n",
    "# for file in weather_files:\n",
    "#     weather_df = pd.read_pickle(f'./data/{file}')\n",
    "#     cleaned_df = clean_weather_data(weather_df)\n",
    "#     cleaned_df.to_pickle(f'./data/clean_{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stn</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>da</th>\n",
       "      <th>temp</th>\n",
       "      <th>stp</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>prcp</th>\n",
       "      <th>thunder</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>690140</td>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "      <td>68.1</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>78.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>690140</td>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "      <td>66.8</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>690140</td>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>64.7</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>690140</td>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>07</td>\n",
       "      <td>54.9</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>690140</td>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>08</td>\n",
       "      <td>57.4</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stn  year  mo  da  temp     stp wdsp  max_temp  prcp thunder       date\n",
       "8   690140  1999  01  04  68.1  9999.9  2.4      78.8   0.0       0 1999-01-04\n",
       "10  690140  1999  01  05  66.8  9999.9  2.6      75.6   0.0       0 1999-01-05\n",
       "14  690140  1999  01  06  64.7  9999.9  1.5      75.6   0.0       0 1999-01-06\n",
       "19  690140  1999  01  07  54.9  9999.9  1.3      72.0   0.0       0 1999-01-07\n",
       "17  690140  1999  01  08  57.4  9999.9  3.0      73.4   0.0       0 1999-01-08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example weather df\n",
    "w1999 = pd.read_pickle('./data/clean_weather1999.pkl')\n",
    "w1999.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='state2station'></a>\n",
    "### Step 3: Create state-to-list-of-stations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ms, sys: 72 µs, total: 44.1 ms\n",
      "Wall time: 43.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "station_locs = defaultdict()\n",
    "#key is state name, value is 2d array of all stations in state (labeled)\n",
    "for group in drop_nulls.groupby('ST'):\n",
    "    station_locs[group[0]] = group[1][[\n",
    "        'LAT', 'LON', 'USAF', 'BEGIN', 'END']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.533 -114.51700000000001 '696454' 19840426 20061214]\n",
      " [32.5 -114.15 '696464' 19900809 20061214]\n",
      " [32.733000000000004 -113.633 '697564' 19830901 19970418]\n",
      " [32.65 -114.617 '699604' 19870701 20121231]\n",
      " [35.650999999999996 -112.148 '720059' 20040408 20040614]]\n"
     ]
    }
   ],
   "source": [
    "#example entry, truncated\n",
    "print(station_locs['AZ'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='near'></a>\n",
    "### Step 4: Find the closest station by coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_sorted_stations(row, station_locs):\n",
    "    '''\n",
    "    Calculate distances to each station from latitude and longitude\n",
    "    Returns a sorted list of stations'''\n",
    "    \n",
    "    location = row[['LATITUDE', 'LONGITUDE']].values.reshape(1, 2)\n",
    "    \n",
    "    # look up state's array of stations and calc distance\n",
    "    state_stations = station_locs[row['STATE']]\n",
    "    dists = cdist(location, state_stations[:, :2])\n",
    "    \n",
    "    # np.argsort returns the indices that would sort the distances\n",
    "    sorted_indices = np.argsort(dists)\n",
    "    return state_stations[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNUSED\n",
    "# def find_closest_station(row, station_locs):\n",
    "#     '''Use 3 closest instead\n",
    "#     '''\n",
    "#     sorted_stations = _get_sorted_stations(row, station_locs).reshape(-1,5)    \n",
    "#     fire_date = row['date_as_int']\n",
    "\n",
    "    \n",
    "#     for station in sorted_stations: \n",
    "#         if fire_date > station[3] and fire_date < station[4]:\n",
    "#             return station[2]  # 2 = USAF idx\n",
    "#         else:\n",
    "#             continue\n",
    "#     print(\"No matching station found for fire\", row['FOD_ID'])\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_3_closest_stations(row, state2stations):\n",
    "    '''Function intended for df.apply\n",
    "    Requires a 'date_as_int' column in df\n",
    "    *Inputs*\n",
    "    row: dataframe row\n",
    "    state2stations: dict, state-to-stations hash map\n",
    "    *Returns* tuple of 3 closest stations that includes the date of the fire \n",
    "    '''\n",
    "    sorted_stations = _get_sorted_stations(row, state2stations).reshape(-1,5) \n",
    "    # get stations info and reshape into an iterable array   \n",
    "    fire_date = row['date_as_int']\n",
    "\n",
    "    #keep track of 3 closest - backups to fill NAs if possible \n",
    "    top_3_stations = []\n",
    "    \n",
    "    # loop through stations, closest first\n",
    "    for station in sorted_stations:\n",
    "        if len(top_3_stations) == 3:\n",
    "            break  \n",
    "            \n",
    "        # take if date is between station's start(3) and end(4) dates\n",
    "        if fire_date > station[3] and fire_date < station[4]: \n",
    "            top_3_stations.append(station[2])  # 2 = USAF idx\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # after 3 stations, return results\n",
    "    if len(top_3_stations) == 0:\n",
    "        print(\"No matching station found for fire\", row['FOD_ID'])\n",
    "        return None, None, None\n",
    "    elif len(top_3_stations) == 1:\n",
    "        return top_3_stations[0], None, None\n",
    "    elif len(top_3_stations) == 2:\n",
    "        return top_3_stations[0], top_3_stations[1], None\n",
    "    else:\n",
    "        return tuple(top_3_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo subset\n",
    "lean_fires = pd.read_pickle('lean_fires.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>FIPS_NAME</th>\n",
       "      <th>hr</th>\n",
       "      <th>Cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334821</th>\n",
       "      <td>343186</td>\n",
       "      <td>2001</td>\n",
       "      <td>2452135.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>B</td>\n",
       "      <td>39.049900</td>\n",
       "      <td>-114.834200</td>\n",
       "      <td>NV</td>\n",
       "      <td>White Pine</td>\n",
       "      <td>033</td>\n",
       "      <td>White Pine</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Lightning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674798</th>\n",
       "      <td>201838989</td>\n",
       "      <td>2013</td>\n",
       "      <td>2456426.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>32.606075</td>\n",
       "      <td>-87.309651</td>\n",
       "      <td>AL</td>\n",
       "      <td>Perry</td>\n",
       "      <td>105</td>\n",
       "      <td>Perry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692175</th>\n",
       "      <td>201862585</td>\n",
       "      <td>2013</td>\n",
       "      <td>2456540.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>31.666004</td>\n",
       "      <td>-96.449247</td>\n",
       "      <td>TX</td>\n",
       "      <td>Limestone</td>\n",
       "      <td>293</td>\n",
       "      <td>Limestone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135865</th>\n",
       "      <td>1385051</td>\n",
       "      <td>2008</td>\n",
       "      <td>2454679.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>33.953889</td>\n",
       "      <td>-116.496944</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130533</th>\n",
       "      <td>131832</td>\n",
       "      <td>2000</td>\n",
       "      <td>2451723.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>B</td>\n",
       "      <td>37.923056</td>\n",
       "      <td>-120.101111</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Lightning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FOD_ID  FIRE_YEAR  DISCOVERY_DATE  FIRE_SIZE FIRE_SIZE_CLASS  \\\n",
       "334821      343186       2001       2452135.5        0.5               B   \n",
       "1674798  201838989       2013       2456426.5        1.0               B   \n",
       "1692175  201862585       2013       2456540.5        1.0               B   \n",
       "1135865    1385051       2008       2454679.5        0.1               A   \n",
       "130533      131832       2000       2451723.5        1.5               B   \n",
       "\n",
       "          LATITUDE   LONGITUDE STATE      COUNTY FIPS_CODE   FIPS_NAME    hr  \\\n",
       "334821   39.049900 -114.834200    NV  White Pine       033  White Pine  14.0   \n",
       "1674798  32.606075  -87.309651    AL       Perry       105       Perry   NaN   \n",
       "1692175  31.666004  -96.449247    TX   Limestone       293   Limestone   NaN   \n",
       "1135865  33.953889 -116.496944    CA        None      None        None   NaN   \n",
       "130533   37.923056 -120.101111    CA        None      None        None  17.0   \n",
       "\n",
       "             Cause  \n",
       "334821   Lightning  \n",
       "1674798   Accident  \n",
       "1692175      Other  \n",
       "1135865      Other  \n",
       "130533   Lightning  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lean_fires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_station(df, state_to_stations):\n",
    "    '''Match fire record with its 3 closest stations\n",
    "    Requires df to have columns \n",
    "    ['LATITUDE', 'LONGITUDE', 'STATE', 'DISCOVERY_DATE']'''\n",
    "    # Preprocess df\n",
    "    if df['DISCOVERY_DATE'].dtype == 'float64':\n",
    "        df['DISCOVERY_DATE'] = pd.to_datetime(df['DISCOVERY_DATE'], origin='julian', unit='D')\n",
    "    df['date_as_int'] = (10000 * df['DISCOVERY_DATE'].dt.year + 100 *\n",
    "                                df['DISCOVERY_DATE'].dt.month + df['DISCOVERY_DATE'].dt.day)\n",
    "    \n",
    "    # Apply function\n",
    "    new_cols = df.apply(find_3_closest_stations, args=(state_to_stations,), axis=1)\n",
    "    print(type(new_cols))\n",
    "    # convert tuples to dataframe\n",
    "    unpackdf = pd.DataFrame(new_cols.tolist(),\n",
    "                            columns=['weather_station1','weather_station2', 'weather_station3'],\n",
    "                            index=new_cols.index)\n",
    "    # append to original df\n",
    "    df = pd.concat([df, unpackdf],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "CPU times: user 34.7 s, sys: 365 ms, total: 35.1 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lean_fires = match_station(lean_fires, station_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_as_int</th>\n",
       "      <th>weather_station1</th>\n",
       "      <th>weather_station2</th>\n",
       "      <th>weather_station3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334821</th>\n",
       "      <td>20010814</td>\n",
       "      <td>724860</td>\n",
       "      <td>725824</td>\n",
       "      <td>724770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674798</th>\n",
       "      <td>20130514</td>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692175</th>\n",
       "      <td>20130905</td>\n",
       "      <td>720779</td>\n",
       "      <td>722469</td>\n",
       "      <td>722561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135865</th>\n",
       "      <td>20080801</td>\n",
       "      <td>722868</td>\n",
       "      <td>747187</td>\n",
       "      <td>720165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130533</th>\n",
       "      <td>20000628</td>\n",
       "      <td>724810</td>\n",
       "      <td>724815</td>\n",
       "      <td>724926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_as_int weather_station1 weather_station2 weather_station3\n",
       "334821      20010814           724860           725824           724770\n",
       "1674798     20130514           999999           999999           999999\n",
       "1692175     20130905           720779           722469           722561\n",
       "1135865     20080801           722868           747187           720165\n",
       "130533      20000628           724810           724815           724926"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new cols\n",
    "lean_fires.iloc[:, -4:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_station1</th>\n",
       "      <th>weather_station2</th>\n",
       "      <th>weather_station3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>49852</td>\n",
       "      <td>49734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2133</td>\n",
       "      <td>2251</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2026</td>\n",
       "      <td>2340</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weather_station1 weather_station2 weather_station3\n",
       "count             50000            49852            49734\n",
       "unique             2133             2251             2355\n",
       "top              999999           999999           999999\n",
       "freq               2026             2340             2818"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lean_fires[['weather_station1','weather_station2', 'weather_station3']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='join'></a>\n",
    "### Step 5: Join Weather\n",
    "I wrote a couple of scripts to join the weather df's from step 2 to the fires data. The core component is a for loop that goes through each year, loads that year's weather data, slices the fire dataframe to that year's subset, and does a left join between fires and weather. \n",
    "\n",
    "The script below joins weather at the closest station on the day after the fire is discovered. Less than 25% of small (classes A,B,C) fires last into the next day, so the weather conditions the next day may have signal on whether a fire continues to get bigger or not. \n",
    "\n",
    "In the full data set, you'll notice there are more columns, such as weather data from the three stations for the first day. This was done with a similar script joining the weather df, just matching on the three different station IDs from Step 4.\n",
    "\n",
    "The other lines of code are are there to accomodate my folder structure and hardware considerations because I needed to split things up into parts and then recombine. Since the core idea of the script is pretty straightforward, I won't adapt the code to demo with the subset here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from datetime import timedelta\n",
    "\n",
    "weather_files = sorted([p for p in os.listdir('./data/') if 'clean_weather' in p])\n",
    "\n",
    "fires = pd.read_pickle('nov_14_fires_joined_3weather_stations.pkl')\n",
    "input_length = len(fires)\n",
    "print(input_length)\n",
    "\n",
    "# Add new date columns \n",
    "fires['day_2'] = fires['DISCOVERY_DATE'] + timedelta(days=1)\n",
    "fires['day_3'] = fires['DISCOVERY_DATE'] + timedelta(days=2)\n",
    "\n",
    "\n",
    "fire_subsets = []\n",
    "n = 0\n",
    "date_col = 'day_2'\n",
    "for filename in weather_files:\n",
    "    \n",
    "    cyear = int(filename[-8:-4]) #magic numbers from file naming\n",
    "    \n",
    "    fires_from_year = fires[fires[date_col].dt.year == cyear]  # slice year\n",
    "    \n",
    "    # Load weather data df for that year\n",
    "    weather_df = pd.read_pickle('./data/{}'.format(filename))\n",
    "\n",
    "    add_day2 = pd.merge(fires_from_year, weather_df, \n",
    "                        how='left', \n",
    "                        left_on=['day_2', 'weather_station1'], \n",
    "                        right_on=['date', 'stn'], \n",
    "                        suffixes=('', '_day2'))\n",
    "    print(add_day2.shape)\n",
    "    \n",
    "    fire_subsets.append(add_day2)end - start)\n",
    "\n",
    "    # Save part once size gets to a certain point \n",
    "    if len(fire_subsets) % 8 == 0:\n",
    "        n += 1\n",
    "        fires_df = pd.concat(fire_subsets, axis=0)\n",
    "        fires_df.to_pickle('dec_4_fires_joined_3weather_days_part{}.pkl'.format(n))\n",
    "        fire_subsets = []\n",
    "        \n",
    "# Merge together\n",
    "part_filenames = sorted([p for p in os.listdir('./') if 'dec_4_fires_joined_3weather_days_part' in p])\n",
    "print(part_filenames)\n",
    "final_parts = []\n",
    "for part in part_filenames:\n",
    "    df = pd.read_pickle(part)\n",
    "    print(part, df.shape)\n",
    "    final_parts.append(df)\n",
    "fires = pd.concat(final_parts, axis=0)\n",
    "\n",
    "#Make sure no rows gained\n",
    "print('Total Rows: ', '\\n Input=', input_length, '\\n Final=', len(fires))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misnamed pickle file - full records with 2 days \n",
    "full_fires = pd.read_pickle('dec_4_fires_joined_3weather_days.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DISCOVERY_TIME2</th>\n",
       "      <th>COUNTY2_x</th>\n",
       "      <th>COUNTY_ID</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>StateID</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>Prev_Lightning_Fires</th>\n",
       "      <th>Prev_Accident_Fires</th>\n",
       "      <th>Prev_Arson_Fires</th>\n",
       "      <th>Prev_Other_Fires</th>\n",
       "      <th>Prev_Fires_at_Location</th>\n",
       "      <th>Prev_Fires_Same_Month</th>\n",
       "      <th>Prev_1_fires2</th>\n",
       "      <th>Prev_2_Fires</th>\n",
       "      <th>Prev_3_fires</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>date_as_int</th>\n",
       "      <th>weather_station</th>\n",
       "      <th>weather_station1</th>\n",
       "      <th>weather_station2</th>\n",
       "      <th>weather_station3</th>\n",
       "      <th>stn_x</th>\n",
       "      <th>year_x</th>\n",
       "      <th>mo_x</th>\n",
       "      <th>da_x</th>\n",
       "      <th>temp_x</th>\n",
       "      <th>stp_x</th>\n",
       "      <th>wdsp_x</th>\n",
       "      <th>max_temp_x</th>\n",
       "      <th>prcp_x</th>\n",
       "      <th>thunder_x</th>\n",
       "      <th>date_x</th>\n",
       "      <th>stn_y</th>\n",
       "      <th>year_y</th>\n",
       "      <th>mo_y</th>\n",
       "      <th>da_y</th>\n",
       "      <th>temp_y</th>\n",
       "      <th>stp_y</th>\n",
       "      <th>wdsp_y</th>\n",
       "      <th>max_temp_y</th>\n",
       "      <th>prcp_y</th>\n",
       "      <th>thunder_y</th>\n",
       "      <th>date_y</th>\n",
       "      <th>stn</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>da</th>\n",
       "      <th>temp</th>\n",
       "      <th>stp</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>prcp</th>\n",
       "      <th>thunder</th>\n",
       "      <th>date</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>stn_day2</th>\n",
       "      <th>year_day2</th>\n",
       "      <th>mo_day2</th>\n",
       "      <th>da_day2</th>\n",
       "      <th>temp_day2</th>\n",
       "      <th>stp_day2</th>\n",
       "      <th>wdsp_day2</th>\n",
       "      <th>max_temp_day2</th>\n",
       "      <th>prcp_day2</th>\n",
       "      <th>thunder_day2</th>\n",
       "      <th>date_day2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1127038</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.00</td>\n",
       "      <td>B</td>\n",
       "      <td>34.391700</td>\n",
       "      <td>-78.568300</td>\n",
       "      <td>NC</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>columbus</td>\n",
       "      <td>37047</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>Accident</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>19920101</td>\n",
       "      <td>723035</td>\n",
       "      <td>723035</td>\n",
       "      <td>723013</td>\n",
       "      <td>746930</td>\n",
       "      <td>723035</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>43.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>723013</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>47.9</td>\n",
       "      <td>1028.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>746930</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>44.1</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>723035</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>46.3</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>878089</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Missing/Undefined</td>\n",
       "      <td>15.00</td>\n",
       "      <td>C</td>\n",
       "      <td>42.240662</td>\n",
       "      <td>-105.292504</td>\n",
       "      <td>WY</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>albany</td>\n",
       "      <td>56001</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1808</td>\n",
       "      <td>19920101</td>\n",
       "      <td>725685</td>\n",
       "      <td>725685</td>\n",
       "      <td>725645</td>\n",
       "      <td>725643</td>\n",
       "      <td>725685</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>27.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>44.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>725645</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>16.8</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>725685</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>35.9</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19096771</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0010</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.58</td>\n",
       "      <td>B</td>\n",
       "      <td>32.132500</td>\n",
       "      <td>-82.761000</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wheeler</td>\n",
       "      <td>13309</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>19920101</td>\n",
       "      <td>722135</td>\n",
       "      <td>722135</td>\n",
       "      <td>722130</td>\n",
       "      <td>722175</td>\n",
       "      <td>722135</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>49.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>722130</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>48.1</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>722175</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>722135</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>54.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19094893</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Smoking</td>\n",
       "      <td>0.72</td>\n",
       "      <td>B</td>\n",
       "      <td>31.121600</td>\n",
       "      <td>-84.215300</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>200.0</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>13205</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Accident</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>19920101</td>\n",
       "      <td>722160</td>\n",
       "      <td>722160</td>\n",
       "      <td>722166</td>\n",
       "      <td>747810</td>\n",
       "      <td>722160</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>48.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>722166</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>747810</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>51.2</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>722160</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>51.1</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100722</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>8.00</td>\n",
       "      <td>B</td>\n",
       "      <td>29.540000</td>\n",
       "      <td>-83.210000</td>\n",
       "      <td>FL</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dixie</td>\n",
       "      <td>12029</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Accident</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>19920101</td>\n",
       "      <td>722120</td>\n",
       "      <td>722120</td>\n",
       "      <td>722146</td>\n",
       "      <td>722055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>722146</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>52.8</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>722055</td>\n",
       "      <td>1992</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>56.5</td>\n",
       "      <td>9999.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FOD_ID DISCOVERY_DATE  DISCOVERY_DOY DISCOVERY_TIME  STAT_CAUSE_CODE  \\\n",
       "0   1127038     1992-01-01              1           None              5.0   \n",
       "1    878089     1992-01-01              1           None             13.0   \n",
       "2  19096771     1992-01-01              1           0010              9.0   \n",
       "3  19094893     1992-01-01              1           0200              3.0   \n",
       "4   1100722     1992-01-01              1           None              2.0   \n",
       "\n",
       "    STAT_CAUSE_DESCR  FIRE_SIZE FIRE_SIZE_CLASS   LATITUDE   LONGITUDE STATE  \\\n",
       "0     Debris Burning       5.00               B  34.391700  -78.568300    NC   \n",
       "1  Missing/Undefined      15.00               C  42.240662 -105.292504    WY   \n",
       "2      Miscellaneous       0.58               B  32.132500  -82.761000    GA   \n",
       "3            Smoking       0.72               B  31.121600  -84.215300    GA   \n",
       "4      Equipment Use       8.00               B  29.540000  -83.210000    FL   \n",
       "\n",
       "   Month  DayofWeek  DISCOVERY_TIME2             COUNTY2_x COUNTY_ID CLASS  \\\n",
       "0      1  Wednesday              NaN              columbus     37047     1   \n",
       "1      1  Wednesday              NaN                albany     56001     2   \n",
       "2      1  Wednesday             10.0  wheeler                  13309     1   \n",
       "3      1  Wednesday            200.0  mitchell                 13205     1   \n",
       "4      1  Wednesday              NaN                 dixie     12029     1   \n",
       "\n",
       "  StateID     CAUSE  Prev_Lightning_Fires  Prev_Accident_Fires  \\\n",
       "0      37  Accident                   0.0                  0.0   \n",
       "1      56     Other                   0.0                  0.0   \n",
       "2      13     Other                   0.0                  0.0   \n",
       "3      13  Accident                   0.0                  0.0   \n",
       "4      12  Accident                   0.0                  0.0   \n",
       "\n",
       "   Prev_Arson_Fires  Prev_Other_Fires  Prev_Fires_at_Location  \\\n",
       "0               0.0               0.0                     0.0   \n",
       "1               0.0               0.0                     0.0   \n",
       "2               0.0               0.0                     0.0   \n",
       "3               0.0               0.0                     0.0   \n",
       "4               0.0               0.0                     0.0   \n",
       "\n",
       "   Prev_Fires_Same_Month  Prev_1_fires2  Prev_2_Fires  Prev_3_fires Elevation  \\\n",
       "0                    0.0            0.0           0.0           0.0        29   \n",
       "1                    0.0            0.0           0.0           0.0      1808   \n",
       "2                    0.0            0.0           0.0           0.0        59   \n",
       "3                    0.0            0.0           0.0           0.0        71   \n",
       "4                    0.0            0.0           0.0           0.0         7   \n",
       "\n",
       "   date_as_int weather_station weather_station1 weather_station2  \\\n",
       "0     19920101          723035           723035           723013   \n",
       "1     19920101          725685           725685           725645   \n",
       "2     19920101          722135           722135           722130   \n",
       "3     19920101          722160           722160           722166   \n",
       "4     19920101          722120           722120           722146   \n",
       "\n",
       "  weather_station3   stn_x year_x mo_x da_x  temp_x   stp_x wdsp_x  \\\n",
       "0           746930  723035   1992   01   01    43.5  9999.9    8.0   \n",
       "1           725643  725685   1992   01   01    27.5  9999.9    4.2   \n",
       "2           722175  722135   1992   01   01    49.5  9999.9    7.8   \n",
       "3           747810  722160   1992   01   01    48.5  9999.9    9.7   \n",
       "4           722055     NaN    NaN  NaN  NaN     NaN     NaN    NaN   \n",
       "\n",
       "   max_temp_x  prcp_x thunder_x     date_x   stn_y year_y mo_y da_y  temp_y  \\\n",
       "0        55.0     0.0         0 1992-01-01  723013   1992   01   01    47.9   \n",
       "1        44.1     0.0         0 1992-01-01  725645   1992   01   01    16.8   \n",
       "2        55.0     0.0         0 1992-01-01  722130   1992   01   01    48.1   \n",
       "3        57.0     0.0         0 1992-01-01  722166   1992   01   01    50.0   \n",
       "4         NaN     NaN       NaN        NaT  722146   1992   01   01    52.8   \n",
       "\n",
       "    stp_y wdsp_y  max_temp_y  prcp_y thunder_y     date_y     stn  year   mo  \\\n",
       "0  1028.2    8.7        66.9    0.00         0 1992-01-01  746930  1992   01   \n",
       "1  9999.9    3.7        28.2    0.04         0 1992-01-01     NaN   NaN  NaN   \n",
       "2  1020.1    9.9        55.9    0.00         0 1992-01-01  722175  1992   01   \n",
       "3  9999.9   11.5        61.0    0.00         0 1992-01-01  747810  1992   01   \n",
       "4  1017.2   10.0        61.0    0.00         0 1992-01-01  722055  1992   01   \n",
       "\n",
       "    da  temp     stp wdsp  max_temp  prcp thunder       date      day_2  \\\n",
       "0   01  44.1  9999.9  5.9      54.0   0.0       0 1992-01-01 1992-01-02   \n",
       "1  NaN   NaN     NaN  NaN       NaN   NaN     NaN        NaT 1992-01-02   \n",
       "2   01  45.0  9999.9  6.7      55.0   0.0       0 1992-01-01 1992-01-02   \n",
       "3   01  51.2  9999.9  8.2      55.9   0.0       0 1992-01-01 1992-01-02   \n",
       "4   01  56.5  9999.9  7.4      57.9   0.0       0 1992-01-01 1992-01-02   \n",
       "\n",
       "       day_3 stn_day2 year_day2 mo_day2 da_day2  temp_day2  stp_day2  \\\n",
       "0 1992-01-03   723035      1992      01      02       46.3    9999.9   \n",
       "1 1992-01-03   725685      1992      01      02       35.9    9999.9   \n",
       "2 1992-01-03   722135      1992      01      02       54.5    9999.9   \n",
       "3 1992-01-03   722160      1992      01      02       51.1    9999.9   \n",
       "4 1992-01-03      NaN       NaN     NaN     NaN        NaN       NaN   \n",
       "\n",
       "  wdsp_day2  max_temp_day2  prcp_day2 thunder_day2  date_day2  \n",
       "0       6.7           54.0       0.00            0 1992-01-02  \n",
       "1       7.5           48.9       0.00            0 1992-01-02  \n",
       "2       6.8           63.0       0.20            0 1992-01-02  \n",
       "3       9.5           55.9       0.12            0 1992-01-02  \n",
       "4       NaN            NaN        NaN          NaN        NaT  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "full_fires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1880443 entries, 0 to 74501\n",
      "Data columns (total 80 columns):\n",
      "FOD_ID                    int64\n",
      "DISCOVERY_DATE            datetime64[ns]\n",
      "DISCOVERY_DOY             int64\n",
      "DISCOVERY_TIME            object\n",
      "STAT_CAUSE_CODE           float64\n",
      "STAT_CAUSE_DESCR          object\n",
      "FIRE_SIZE                 float64\n",
      "FIRE_SIZE_CLASS           object\n",
      "LATITUDE                  float64\n",
      "LONGITUDE                 float64\n",
      "STATE                     object\n",
      "Month                     int64\n",
      "DayofWeek                 object\n",
      "DISCOVERY_TIME2           float64\n",
      "COUNTY2_x                 object\n",
      "COUNTY_ID                 object\n",
      "CLASS                     category\n",
      "StateID                   object\n",
      "CAUSE                     object\n",
      "Prev_Lightning_Fires      float64\n",
      "Prev_Accident_Fires       float64\n",
      "Prev_Arson_Fires          float64\n",
      "Prev_Other_Fires          float64\n",
      "Prev_Fires_at_Location    float64\n",
      "Prev_Fires_Same_Month     float64\n",
      "Prev_1_fires2             float64\n",
      "Prev_2_Fires              float64\n",
      "Prev_3_fires              float64\n",
      "Elevation                 object\n",
      "date_as_int               int64\n",
      "weather_station           object\n",
      "weather_station1          object\n",
      "weather_station2          object\n",
      "weather_station3          object\n",
      "stn_x                     object\n",
      "year_x                    object\n",
      "mo_x                      object\n",
      "da_x                      object\n",
      "temp_x                    float64\n",
      "stp_x                     float64\n",
      "wdsp_x                    object\n",
      "max_temp_x                float64\n",
      "prcp_x                    float64\n",
      "thunder_x                 object\n",
      "date_x                    datetime64[ns]\n",
      "stn_y                     object\n",
      "year_y                    object\n",
      "mo_y                      object\n",
      "da_y                      object\n",
      "temp_y                    float64\n",
      "stp_y                     float64\n",
      "wdsp_y                    object\n",
      "max_temp_y                float64\n",
      "prcp_y                    float64\n",
      "thunder_y                 object\n",
      "date_y                    datetime64[ns]\n",
      "stn                       object\n",
      "year                      object\n",
      "mo                        object\n",
      "da                        object\n",
      "temp                      float64\n",
      "stp                       float64\n",
      "wdsp                      object\n",
      "max_temp                  float64\n",
      "prcp                      float64\n",
      "thunder                   object\n",
      "date                      datetime64[ns]\n",
      "day_2                     datetime64[ns]\n",
      "day_3                     datetime64[ns]\n",
      "stn_day2                  object\n",
      "year_day2                 object\n",
      "mo_day2                   object\n",
      "da_day2                   object\n",
      "temp_day2                 float64\n",
      "stp_day2                  float64\n",
      "wdsp_day2                 object\n",
      "max_temp_day2             float64\n",
      "prcp_day2                 float64\n",
      "thunder_day2              object\n",
      "date_day2                 datetime64[ns]\n",
      "dtypes: category(1), datetime64[ns](7), float64(30), int64(4), object(38)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "full_fires.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
