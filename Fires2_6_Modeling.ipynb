{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "I begin developing a model for predicting wildfire size class with basic scraped features. Major point established so far is that scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 60)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "# ignore warning when preds doesn't predict rare class\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global random seed for sklearn\n",
    "np.random.seed(2019) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('train_fires.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop pipeline\n",
    "Use a smaller subset to develop code and work through issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, _  = train_test_split(data, test_size=0.8, stratify=data['CLASS'])\n",
    "# switching over to 3 class problem for easier interpretation of results\n",
    "# Small(1): < 10 acres burned (A,B)\n",
    "# Medium(2): 10-1000 acres (C, D, E)\n",
    "# Large(3): > 1000 acres (F,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310542, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    157827\n",
       "A    107857\n",
       "C     36243\n",
       "D      4613\n",
       "E      2232\n",
       "F      1193\n",
       "G       577\n",
       "Name: FIRE_SIZE_CLASS, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['FIRE_SIZE_CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    271506\n",
       "2     37340\n",
       "3      1696\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310542, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(columns='FIRE_SIZE_CLASS')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f95a585b8d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.log10(train['FIRE_SIZE']))\n",
    "# not log normal - big peak of fires less than 1 acre\n",
    "# partly why I did classification since the exact size is unimportant\n",
    "# more important is the response needed\n",
    "# 1: local firefighters, 2: maybe several teams, 3: bring in reinforcements, feds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOD_ID                       int64\n",
       "DISCOVERY_DATE      datetime64[ns]\n",
       "FIRE_SIZE                  float64\n",
       "LATITUDE                   float64\n",
       "LONGITUDE                  float64\n",
       "Month                        int64\n",
       "DayofWeek                   object\n",
       "COUNTY2_x                   object\n",
       "COUNTY_ID                   object\n",
       "CLASS                     category\n",
       "StateID                     object\n",
       "Elevation                  float64\n",
       "weather_station1            object\n",
       "stn_x                       object\n",
       "year_x                      object\n",
       "temp_x                     float64\n",
       "stp_x                      float64\n",
       "wdsp_x                     float64\n",
       "max_temp_x                 float64\n",
       "prcp_x                     float64\n",
       "thunder_x                   object\n",
       "date_x              datetime64[ns]\n",
       "day_2               datetime64[ns]\n",
       "year_day2                   object\n",
       "temp_day2                  float64\n",
       "stp_day2                   float64\n",
       "wdsp_day2                  float64\n",
       "max_temp_day2              float64\n",
       "prcp_day2                  float64\n",
       "thunder_day2                object\n",
       "date_day2           datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for scaling when some cols are not suited\n",
    "# scaler = StandardScaler()\n",
    "# X_subset = scaler.fit_transform(X[:,[0,1]])\n",
    "# X_last_column = X[:, 2]\n",
    "# X_std = np.concatenate((X_subset, X_last_column[:, np.newaxis]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_features(model, train, target, splits=5):\n",
    "    \n",
    "    starttime = time.time()\n",
    "    # separate input df into features and target\n",
    "    print(\"original length\", len(train))\n",
    "    train = train.dropna() # just drop for now\n",
    "    print(\"dropped na's\", len(train))\n",
    "    y = train[target]\n",
    "    X = train.drop(columns=target)\n",
    "    # get indices to look up float columns \n",
    "#     float_indices = [i for i, col in enumerate(X.columns) if X[col].dtype == 'float64']\n",
    "    \n",
    "     \n",
    "    kf = StratifiedKFold(n_splits=splits)\n",
    "#     imp = Imputer()\n",
    "    scaler = StandardScaler()\n",
    "    fs = []\n",
    "    ps = []\n",
    "    rs = []\n",
    "    classes = [1,2,3]\n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X, y):\n",
    "        # split data on indices\n",
    "        # \"take\" indexes according to position of element, not index values\n",
    "        train_X = X.take(train_ind)\n",
    "        train_y = y.take(train_ind)\n",
    "#         print('train', train_y.value_counts()/len(train_y)) # confirm kf worked\n",
    "        val_X = X.take(val_ind)\n",
    "        val_y = y.take(val_ind)\n",
    "#         print('val', val_y.value_counts()/len(train_y))\n",
    "        # normalize float columns for train\n",
    "        float_cols = train_X.select_dtypes(include='float64')\n",
    "\n",
    "        float_cols = scaler.fit_transform(float_cols)\n",
    "        # recombine \n",
    "        other_cols = train_X.select_dtypes(exclude='float64')\n",
    "        train_X_norm = np.concatenate((float_cols, other_cols), axis=1)\n",
    "        \n",
    "        # fit model    \n",
    "        model.fit(train_X_norm, train_y)\n",
    "        \n",
    "        # normalize float columns for val\n",
    "        float_cols = val_X.select_dtypes(include='float64')\n",
    "\n",
    "        float_cols = scaler.transform(float_cols)\n",
    "        other_cols = val_X.select_dtypes(exclude='float64')\n",
    "        val_X_norm = np.concatenate((float_cols, other_cols), axis=1)\n",
    "        \n",
    "        # predict \n",
    "        model_preds = model.predict(val_X_norm)\n",
    "        \n",
    "        # generate scores\n",
    "        fs.append(f1_score(val_y, model_preds, labels=classes, average=None))\n",
    "        ps.append(precision_score(val_y, model_preds, labels=classes, average=None))\n",
    "        rs.append(recall_score(val_y, model_preds, labels=classes, average=None))\n",
    "    \n",
    "    endtime = time.time()\n",
    "    print('Run time:', endtime - starttime)\n",
    "    # print last one\n",
    "    print(confusion_matrix(val_y, model_preds, labels=classes)) \n",
    "    print(classification_report(val_y, model_preds, labels=classes))\n",
    "    \n",
    "    # return mean over the 5 folds\n",
    "    print('f1 -- precision -- recall')\n",
    "    return np.mean(fs,axis=0), np.mean(ps,axis=0), np.mean(rs,axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with old baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310542\n",
      "Run time: 2.960841417312622\n",
      "[[54301     0     0]\n",
      " [ 7468     0     0]\n",
      " [  339     0     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     54301\n",
      "          2       0.00      0.00      0.00      7468\n",
      "          3       0.00      0.00      0.00       339\n",
      "\n",
      "avg / total       0.76      0.87      0.82     62108\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.93293337, 0.        , 0.        ]),\n",
       " array([0.8742972, 0.       , 0.       ]),\n",
       " array([1., 0., 0.]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = train[['LONGITUDE', 'CLASS']]\n",
    "cv_features(lr, df1, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310314\n",
      "Run time: 5.724637508392334\n",
      "[[54265     0     0]\n",
      " [ 7459     0     0]\n",
      " [  338     0     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     54265\n",
      "          2       0.00      0.00      0.00      7459\n",
      "          3       0.00      0.00      0.00       338\n",
      "\n",
      "avg / total       0.76      0.87      0.82     62062\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.93296885, 0.        , 0.        ]),\n",
       " array([0.87435952, 0.        , 0.        ]),\n",
       " array([1., 0., 0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try most promising feature from weather data as alternative logit baseline\n",
    "df2 = train[['max_temp_x', 'CLASS']]\n",
    "cv_features(lr, df2, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310314\n",
      "Run time: 82.87573313713074\n",
      "[[37925 16340     0]\n",
      " [ 5423  2036     0]\n",
      " [  190   148     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.70      0.78     54265\n",
      "          2       0.11      0.27      0.16      7459\n",
      "          3       0.00      0.00      0.00       338\n",
      "\n",
      "avg / total       0.77      0.64      0.70     62062\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.80104555, 0.1265181 , 0.        ]),\n",
       " array([0.8716049 , 0.08794594, 0.        ]),\n",
       " array([0.75000963, 0.22677051, 0.        ]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move on to vanilla random forest, keeping number of trees low for run time\n",
    "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "cv_features(rf, df2, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FOD_ID', 'DISCOVERY_DATE', 'FIRE_SIZE', 'LATITUDE', 'LONGITUDE',\n",
       "       'Month', 'DayofWeek', 'COUNTY2_x', 'COUNTY_ID', 'CLASS', 'StateID',\n",
       "       'Elevation', 'weather_station1', 'stn_x', 'year_x', 'temp_x', 'stp_x',\n",
       "       'wdsp_x', 'max_temp_x', 'prcp_x', 'thunder_x', 'date_x', 'day_2',\n",
       "       'year_day2', 'temp_day2', 'stp_day2', 'wdsp_day2', 'max_temp_day2',\n",
       "       'prcp_day2', 'thunder_day2', 'date_day2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n",
      "Run time: 123.5555477142334\n",
      "[[51790   377     0]\n",
      " [ 7131    63     0]\n",
      " [  318     5     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.99      0.93     52167\n",
      "          2       0.14      0.01      0.02      7194\n",
      "          3       0.00      0.00      0.00       323\n",
      "\n",
      "avg / total       0.78      0.87      0.81     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92695268, 0.02126689, 0.        ]),\n",
       " array([0.87428867, 0.07373504, 0.        ]),\n",
       " array([0.9866544 , 0.01504031, 0.        ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more weather features\n",
    "df3 = train[['wdsp_x','max_temp_x', 'prcp_x', 'CLASS']]\n",
    "cv_features(rf, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 295368\n",
      "Run time: 378.57324719429016\n",
      "[[51626     0     0]\n",
      " [ 7129     0     0]\n",
      " [  318     0     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     51626\n",
      "          2       0.00      0.00      0.00      7129\n",
      "          3       0.00      0.00      0.00       318\n",
      "\n",
      "avg / total       0.76      0.87      0.82     59073\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9.31209540e-01, 4.45558340e-04, 9.85221675e-04]),\n",
       " array([8.73839345e-01, 3.01886792e-02, 6.66666667e-04]),\n",
       " array([9.96664471e-01, 2.24435405e-04, 1.88679245e-03]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in more weather, including day 2, and class weights\n",
    "df4 = train[['wdsp_x','max_temp_x', 'prcp_x','thunder_x', 'wdsp_day2',\n",
    "       'max_temp_day2', 'CLASS']]\n",
    "rfw = RandomForestClassifier(n_estimators=300, \n",
    "                             class_weight={1:1, 2:5, 3:80})\n",
    "cv_features(rfw, df4, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310314\n",
      "Run time: 437.46885800361633\n",
      "[[54265     0     0]\n",
      " [ 7459     0     0]\n",
      " [  338     0     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     54265\n",
      "          2       0.00      0.00      0.00      7459\n",
      "          3       0.00      0.00      0.00       338\n",
      "\n",
      "avg / total       0.76      0.87      0.82     62062\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.93296885, 0.        , 0.        ]),\n",
       " array([0.87435952, 0.        , 0.        ]),\n",
       " array([1., 0., 0.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try something different\n",
    "df5 = train[['LONGITUDE', 'Elevation', 'max_temp_x','CLASS']]\n",
    "cv_features(rfw, df5, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n",
      "Run time: 126.36591100692749\n",
      "[[51989   178     0]\n",
      " [ 7168    26     0]\n",
      " [  322     1     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     52167\n",
      "          2       0.13      0.00      0.01      7194\n",
      "          3       0.00      0.00      0.00       323\n",
      "\n",
      "avg / total       0.78      0.87      0.81     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92884825, 0.01518054, 0.        ]),\n",
       " array([0.87411022, 0.09476372, 0.        ]),\n",
       " array([0.99101349, 0.0095357 , 0.        ]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try balanced class weights\n",
    "rfwb = RandomForestClassifier(n_estimators=300, \n",
    "                             class_weight=\"balanced\",\n",
    "                             n_jobs=-1)\n",
    "cv_features(rfwb, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310542\n",
      "Run time: 14.838520526885986\n",
      "[[54301     0     0]\n",
      " [ 7468     0     0]\n",
      " [  319    20     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93     54301\n",
      "          2       0.00      0.00      0.00      7468\n",
      "          3       0.00      0.00      0.00       339\n",
      "\n",
      "avg / total       0.76      0.87      0.82     62108\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.93314178, 0.        , 0.        ]),\n",
       " array([0.87466336, 0.        , 0.        ]),\n",
       " array([1., 0., 0.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfect predict in theory\n",
    "fire_size = train[['FIRE_SIZE', 'CLASS']]\n",
    "cv_features(lr, fire_size, 'CLASS')\n",
    "# fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative with no scaling\n",
    "\n",
    "def unscaled_cv_features(model, train, target, splits=5):\n",
    "    \n",
    "    starttime = time.time()\n",
    "    # separate input df into features and target\n",
    "    print(\"original length\", len(train))\n",
    "    train = train.dropna() # just drop for now\n",
    "    print(\"dropped na's\", len(train))\n",
    "    y = train[target]\n",
    "    X = train.drop(columns=target)\n",
    "         \n",
    "    kf = StratifiedKFold(n_splits=splits)\n",
    "    fs = []\n",
    "    ps = []\n",
    "    rs = []\n",
    "    classes = [1,2,3]\n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X, y):\n",
    "        # split data on indices\n",
    "        # \"take\" indexes according to position of element, not index values\n",
    "        train_X = X.take(train_ind).values\n",
    "        train_y = y.take(train_ind).values\n",
    "#         print('train', train_y.value_counts()/len(train_y)) # confirm kf worked\n",
    "        val_X = X.take(val_ind).values\n",
    "        val_y = y.take(val_ind).values\n",
    "        \n",
    "        # fit model    \n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        # predict \n",
    "        model_preds = model.predict(val_X)\n",
    "        \n",
    "        # generate scores\n",
    "        fs.append(f1_score(val_y, model_preds, labels=classes, average=None))\n",
    "        ps.append(precision_score(val_y, model_preds, labels=classes, average=None))\n",
    "        rs.append(recall_score(val_y, model_preds, labels=classes, average=None))\n",
    "        \n",
    "    # print last one\n",
    "    print(confusion_matrix(val_y, model_preds, labels=classes)) \n",
    "    print(classification_report(val_y, model_preds, labels=classes))\n",
    "    \n",
    "    # return mean over the 5 folds\n",
    "    print('f1 -- precision -- recall')\n",
    "    return np.mean(fs,axis=0), np.mean(ps,axis=0), np.mean(rs,axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[54301     0     0]\n",
      " [    0  7468     0]\n",
      " [    0     0   339]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00     54301\n",
      "          2       1.00      1.00      1.00      7468\n",
      "          3       1.00      1.00      1.00       339\n",
      "\n",
      "avg / total       1.00      1.00      1.00     62108\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfect as you would expect \n",
    "unscaled_cv_features(rf, fire_size, 'CLASS')\n",
    "# conclusion: standard scaler not appropriate for fire size\n",
    "# also inappropriate: wdspd, prcp, elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[54301     0     0]\n",
      " [  197  7252    19]\n",
      " [    0     0   339]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00     54301\n",
      "          2       1.00      0.97      0.99      7468\n",
      "          3       0.95      1.00      0.97       339\n",
      "\n",
      "avg / total       1.00      1.00      1.00     62108\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.99807193, 0.98415184, 0.96697374]),\n",
       " array([0.99615131, 1.        , 0.93612884]),\n",
       " array([1.        , 0.96880021, 1.        ]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_cv_features(lr, fire_size, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n",
      "[[33876 13651  4640]\n",
      " [ 4288  2236   670]\n",
      " [  181    97    45]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.88      0.65      0.75     52167\n",
      "          2       0.14      0.31      0.19      7194\n",
      "          3       0.01      0.14      0.02       323\n",
      "\n",
      "avg / total       0.79      0.61      0.68     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.74628301, 0.18989398, 0.01639167]),\n",
       " array([0.88217895, 0.13762909, 0.00868385]),\n",
       " array([0.64667342, 0.30618259, 0.14585101]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try balanced class weights\n",
    "rfwb = RandomForestClassifier(n_estimators=300, \n",
    "                             class_weight=\"balanced\",\n",
    "                             n_jobs=-1)\n",
    "unscaled_cv_features(rfwb, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialized_cv_features(model, train, target, splits=5):\n",
    "    '''currently hard coded to have only max_temp_x to be normalized with standard\n",
    "    scaler, other floats normalized with min max'''\n",
    "    starttime = time.time()\n",
    "    # separate input df into features and target\n",
    "    print(\"original length\", len(train))\n",
    "    train = train.dropna() # just drop for now\n",
    "    print(\"dropped na's\", len(train))\n",
    "    y = train[target]\n",
    "    X = train.drop(columns=target)\n",
    "    # get indices to look up float columns \n",
    "#     float_indices = [i for i, col in enumerate(X.columns) if X[col].dtype == 'float64']\n",
    "    \n",
    "     \n",
    "    kf = StratifiedKFold(n_splits=splits)\n",
    "#     imp = Imputer()\n",
    "    scaler = StandardScaler()\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    fs = []\n",
    "    ps = []\n",
    "    rs = []\n",
    "    classes = [1,2,3]\n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X, y):\n",
    "        # split data on indices\n",
    "        # \"take\" indexes according to position of element, not index values\n",
    "        train_X = X.take(train_ind)\n",
    "        train_y = y.take(train_ind)\n",
    "#         print('train', train_y.value_counts()/len(train_y)) # confirm kf worked\n",
    "        val_X = X.take(val_ind)\n",
    "        val_y = y.take(val_ind)\n",
    "#         print('val', val_y.value_counts()/len(train_y))\n",
    "        # normalize temp columns for train\n",
    "        ss_cols = train_X.pop('max_temp_x').values.reshape(-1,1)\n",
    "        ss_cols = scaler.fit_transform(ss_cols)\n",
    "        # min max scale \n",
    "        mm_cols = train_X.select_dtypes(include='float64')\n",
    "        mm_cols = min_max_scaler.fit_transform(mm_cols)\n",
    "        # recombine \n",
    "        other_cols = train_X.select_dtypes(exclude='float64')\n",
    "        train_X_norm = np.concatenate((ss_cols, mm_cols,other_cols), axis=1)\n",
    "#         print(train_X_norm.shape)\n",
    "#         print(train_X_norm[:5])\n",
    "        # fit model    \n",
    "        model.fit(train_X_norm, train_y)\n",
    "        \n",
    "        # normalize float columns for val\n",
    "        ss_cols = val_X.pop('max_temp_x').values.reshape(-1,1)\n",
    "        ss_cols = scaler.transform(ss_cols)\n",
    "        \n",
    "        mm_cols = val_X.select_dtypes(include='float64')\n",
    "        mm_cols = min_max_scaler.transform(mm_cols)\n",
    "        other_cols = val_X.select_dtypes(exclude='float64')\n",
    "        val_X_norm = np.concatenate((ss_cols, mm_cols, other_cols), axis=1)\n",
    "#         print(val_X_norm[:5])\n",
    "#         print(val_X_norm.shape)\n",
    "        # predict \n",
    "        model_preds = model.predict(val_X_norm)\n",
    "        \n",
    "        # generate scores\n",
    "        fs.append(f1_score(val_y, model_preds, labels=classes, average=None))\n",
    "        ps.append(precision_score(val_y, model_preds, labels=classes, average=None))\n",
    "        rs.append(recall_score(val_y, model_preds, labels=classes, average=None))\n",
    "    \n",
    "    endtime = time.time()\n",
    "    print('Run time:', endtime - starttime)\n",
    "    # print last one\n",
    "    print(confusion_matrix(val_y, model_preds, labels=classes)) \n",
    "    print(classification_report(val_y, model_preds, labels=classes))\n",
    "    \n",
    "    # return mean over the 5 folds\n",
    "    print('f1 -- precision -- recall')\n",
    "    return np.mean(fs,axis=0), np.mean(ps,axis=0), np.mean(rs,axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n",
      "Run time: 114.66828918457031\n",
      "[[33893 13625  4649]\n",
      " [ 4303  2226   665]\n",
      " [  182    96    45]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.88      0.65      0.75     52167\n",
      "          2       0.14      0.31      0.19      7194\n",
      "          3       0.01      0.14      0.02       323\n",
      "\n",
      "avg / total       0.79      0.61      0.68     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.74606342, 0.18927584, 0.0164079 ]),\n",
       " array([0.88195102, 0.13715881, 0.00869296]),\n",
       " array([0.64646639, 0.30529295, 0.1458491 ]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should give same result as above -yes\n",
    "specialized_cv_features(rfwb, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 310314\n",
      "Run time: 194.32654309272766\n",
      "[[53236  1012    17]\n",
      " [ 7024   425    10]\n",
      " [  317    16     5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.88      0.98      0.93     54265\n",
      "          2       0.29      0.06      0.10      7459\n",
      "          3       0.16      0.01      0.03       338\n",
      "\n",
      "avg / total       0.80      0.86      0.82     62062\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92741027, 0.10038428, 0.01663666]),\n",
       " array([0.879129  , 0.30489696, 0.14836658]),\n",
       " array([0.98130293, 0.06008523, 0.00887225]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try elevation again\n",
    "specialized_cv_features(rfwb, df5, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling doesn't matter for RF but is important for Logit and gradient boosting models.\n",
    "# Also haven't tried tuning RF hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Multinomial Logit - helps with ordered categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n",
      "Run time: 15.187665224075317\n",
      "[[23824  9767 18576]\n",
      " [ 2917  1620  2657]\n",
      " [   64    40   219]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.46      0.60     52167\n",
      "          2       0.14      0.23      0.17      7194\n",
      "          3       0.01      0.68      0.02       323\n",
      "\n",
      "avg / total       0.79      0.43      0.55     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.60464441, 0.16811054, 0.01953523]),\n",
       " array([0.88750701, 0.1373227 , 0.00991545]),\n",
       " array([0.45851448, 0.21672428, 0.65514467]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrwb = LogisticRegression(C=1, class_weight='balanced', \n",
    "                          multi_class='multinomial',\n",
    "                          solver='newton-cg',\n",
    "                          max_iter=300)\n",
    "specialized_cv_features(lrwb, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length 310542\n",
      "dropped na's 298428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/douglas/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 20.628525018692017\n",
      "[[13130 33689  5348]\n",
      " [ 1632  4684   878]\n",
      " [   44   178   101]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.25      0.39     52167\n",
      "          2       0.12      0.65      0.20      7194\n",
      "          3       0.02      0.31      0.03       323\n",
      "\n",
      "avg / total       0.79      0.30      0.37     59684\n",
      "\n",
      "f1 -- precision -- recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.39388729, 0.20578148, 0.03154879]),\n",
       " array([0.89010987, 0.12213207, 0.01657402]),\n",
       " array([0.25291943, 0.6532022 , 0.32757329]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrw = LogisticRegression(C=1, class_weight={1:1, 2:8, 3:100}, \n",
    "                          multi_class='multinomial',\n",
    "                          solver='newton-cg',\n",
    "                          max_iter=500)\n",
    "specialized_cv_features(lrw, df3, 'CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial logit seems promising - revolves around log-cumulative odds \n",
    "# how does sklearn implement?\n",
    "\n",
    "# Oversampling might extract more info from the rare classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_indices = [i for i, col in enumerate(train.columns) if train[col].dtype == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.select_dtypes(exclude='float64').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null checking\n",
    "# train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['max_temp_x'].isnull()].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
